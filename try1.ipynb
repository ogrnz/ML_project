{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60af8b05",
   "metadata": {},
   "source": [
    "## ML competition\n",
    "\n",
    "_Marilyn, Shiva, Olivier_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "003e3bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12d0fcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup chunk\n",
    "\n",
    "import time\n",
    "\n",
    "# Custom utils\n",
    "from utils import *\n",
    "\n",
    "# Data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Text sanitization\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "try:\n",
    "    # Avoid error if you don't have the resource\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "except LookupError:\n",
    "    nltk.download(\"stopwords\")\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    \n",
    "stemmer = SnowballStemmer(language=\"english\")\n",
    "\n",
    "# Lang detection\n",
    "#import langid\n",
    "#from langid.langid import LanguageIdentifier, model\n",
    "#identifier = LanguageIdentifier.from_modelstring(model, norm_probs=True)\n",
    "\n",
    "# Misc\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Define the seed for reproducibility\n",
    "SEED = 31415\n",
    "# Define n_jobs\n",
    "JOBS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ebad316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit time\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis,\n",
    "    QuadraticDiscriminantAnalysis,\n",
    ")\n",
    "\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer, \n",
    "    TfidfTransformer, \n",
    "    TfidfVectorizer\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    GridSearchCV, \n",
    "    KFold, \n",
    "    cross_val_score\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    accuracy_score, \n",
    "    confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df0adae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/MLUnige2021_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31d0f9e",
   "metadata": {},
   "source": [
    "### 1. EDA\n",
    "Small EDA to check a bit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd7abc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1280000 entries, 0 to 1279999\n",
      "Data columns (total 7 columns):\n",
      "Id           1280000 non-null int64\n",
      "emotion      1280000 non-null int64\n",
      "tweet_id     1280000 non-null int64\n",
      "date         1280000 non-null object\n",
      "lyx_query    1280000 non-null object\n",
      "user         1280000 non-null object\n",
      "text         1280000 non-null object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 68.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0187a2",
   "metadata": {},
   "source": [
    "More than a million entries. What is `lyx_query`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef294c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NO_QUERY'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lyx_query\"].head()\n",
    "df[\"lyx_query\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066f3afe",
   "metadata": {},
   "source": [
    "Welp only `\"NO_QUERY\"` so we can drop it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f390ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          2063391019\n",
       "1          2000525676\n",
       "2          2218180611\n",
       "3          2190269101\n",
       "4          2069249490\n",
       "              ...    \n",
       "1279995    1835296397\n",
       "1279996    2226720395\n",
       "1279997    1962176213\n",
       "1279998    1976894947\n",
       "1279999    1563596981\n",
       "Name: tweet_id, Length: 1280000, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tweet_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5ec9dd",
   "metadata": {},
   "source": [
    "Those are old tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41783532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Sun Jun 07 02:28:13 PDT 2009\n",
       "1          Mon Jun 01 22:18:53 PDT 2009\n",
       "2          Wed Jun 17 22:01:38 PDT 2009\n",
       "3          Tue Jun 16 02:14:47 PDT 2009\n",
       "4          Sun Jun 07 15:31:58 PDT 2009\n",
       "                       ...             \n",
       "1279995    Mon May 18 05:39:18 PDT 2009\n",
       "1279996    Thu Jun 18 12:18:05 PDT 2009\n",
       "1279997    Fri May 29 10:38:30 PDT 2009\n",
       "1279998    Sat May 30 19:28:13 PDT 2009\n",
       "1279999    Sun Apr 19 23:27:25 PDT 2009\n",
       "Name: date, Length: 1280000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"date\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee652f8",
   "metadata": {},
   "source": [
    "Indeed they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1e13c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "574114"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"user\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d2343b",
   "metadata": {},
   "source": [
    "Lots of different users. If we had only like 1000s of users, we could have looked for some pattern (user X is only positive ...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa8e0271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion                                                    1\n",
       "text       @BreeMe more time to play with you BlackBerry ...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0, [\"emotion\", \"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cbd090d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"emotion\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74f838b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"emotion\"]==1].shape[0] - df[df[\"emotion\"]==0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd9eb90",
   "metadata": {},
   "source": [
    "Perfectly balanced dataset (236 diff between the 2 classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51440464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.bar([\"negative\", \"positive\"], [df[df[\"emotion\"]==0].shape[0], df[df[\"emotion\"]==1].shape[0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27deaf45",
   "metadata": {},
   "source": [
    "Let's also check the language of the tweets (all eng or also others?). For that, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fbb3c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_samp = df.sample(150_000) #Total df takes 1h to run\n",
    "\n",
    "# Commented because we don't want it to run everytime\n",
    "#df_samp[\"lang\"] = df_samp[\"text\"].progress_apply(lang_detect)\n",
    "#df_samp[\"lang\"].unique()\n",
    "#df_samp[~(df_samp[\"lang\"] == \"en\")].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704a8cd6",
   "metadata": {},
   "source": [
    "Only 15k tweets which are not detected as english in our 150k sample. By checking some of the tweets, most are english, but the language detector surely has some trouble with some very short tweets containing one or more foreign words.--> consider all as english!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e8e6f4",
   "metadata": {},
   "source": [
    "## 2. Strategy\n",
    "\n",
    "1. Preprocess the text\n",
    "    1. remove punctuation marks\n",
    "    2. remove stopwords (en)\n",
    "    3. stem or lemmatize the words\n",
    "    \n",
    "    \n",
    "2. take a sample of our whole dataset (200k?) to do our preliminary test. We can't do cross validation on the whole dataset.\n",
    "\n",
    "3. Begin to fit the models. \n",
    "    1. Pipeline with TfidfTransformer (or the other one I don't remember the name)\n",
    "    2. BerNB\n",
    "    3. LogisticRegression\n",
    "    4. RidgeClassifier\n",
    "    5. SGDClassifier\n",
    "    6. SVC\n",
    "    7. RandomForestClassifier\n",
    "    8. DecisionTreeClassifier\n",
    "    9. KNeighborsClassifier\n",
    "    10. LDA? QDA?\n",
    "4. Select a few of the best models, CV with bigger dataset\n",
    "5. ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc71baa",
   "metadata": {},
   "source": [
    "## Misc\n",
    "\n",
    "- Should pay attention to some special chars which were not removed: \"I \\&lt;3 you\" (#2204), at first just remove it, but we could try investigate that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4a0588c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7082"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"text\"].str.contains(\"&lt;3\")].count()\n",
    "(df[df[\"text\"].str.contains(\"&lt;3\")].loc[:, \"emotion\"] == 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170533e7",
   "metadata": {},
   "source": [
    "10635 tweets have that, don't think it's worth it. And out of those, only 7082 are positive. It's not even as sure as that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f000a1",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeb175a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanitized: hello usernam usernam corona \n"
     ]
    }
   ],
   "source": [
    "# Some special strings to test \n",
    "txt1 = \"Hello @Shiva and @Marilyn! https://hello.ch 12334 #corona ...\"\n",
    "print(\"Sanitized:\", sanitize(txt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67819265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a test, sanitize the subsample\n",
    "#df_samp[\"sanitized\"] = df_samp[\"text\"].progress_apply(sanitize)\n",
    "#df_samp.head() #seems good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90ec55a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #If you have an error with sanitized-rec.pkl try to take sanitized.pkl\n",
    "    df_san = pd.read_pickle(\"./data/sanitized.pkl\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No pickle file found, sanitizing existing df\")\n",
    "    \n",
    "    # Sanitize whole dataset\n",
    "    df_san = df.copy()\n",
    "    df_san[\"sanitized\"] = df[\"text\"].progress_apply(sanitize)\n",
    "\n",
    "    # Export it to pickle so we don't have to redo it\n",
    "    df_san.to_pickle(\"./data/sanitized.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e8ebc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280000, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>date</th>\n",
       "      <th>lyx_query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>sanitized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2063391019</td>\n",
       "      <td>Sun Jun 07 02:28:13 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>BerryGurus</td>\n",
       "      <td>@BreeMe more time to play with you BlackBerry ...</td>\n",
       "      <td>time play blackberri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2000525676</td>\n",
       "      <td>Mon Jun 01 22:18:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>peterlanoie</td>\n",
       "      <td>Failed attempt at booting to a flash drive. Th...</td>\n",
       "      <td>fail attempt boot flash drive fail attempt swi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2218180611</td>\n",
       "      <td>Wed Jun 17 22:01:38 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>will_tooker</td>\n",
       "      <td>@msproductions Well ain't that the truth. Wher...</td>\n",
       "      <td>well truth damn auto lock disabl go copi past ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2190269101</td>\n",
       "      <td>Tue Jun 16 02:14:47 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sammutimer</td>\n",
       "      <td>@Meaghery cheers Craig - that was really sweet...</td>\n",
       "      <td>cheer craig realli sweet repli pump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2069249490</td>\n",
       "      <td>Sun Jun 07 15:31:58 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ohaijustin</td>\n",
       "      <td>I was reading the tweets that got send to me w...</td>\n",
       "      <td>read tweet got send lie phone face drop amp hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  emotion    tweet_id                          date lyx_query  \\\n",
       "0   0        1  2063391019  Sun Jun 07 02:28:13 PDT 2009  NO_QUERY   \n",
       "1   1        0  2000525676  Mon Jun 01 22:18:53 PDT 2009  NO_QUERY   \n",
       "2   2        0  2218180611  Wed Jun 17 22:01:38 PDT 2009  NO_QUERY   \n",
       "3   3        1  2190269101  Tue Jun 16 02:14:47 PDT 2009  NO_QUERY   \n",
       "4   4        0  2069249490  Sun Jun 07 15:31:58 PDT 2009  NO_QUERY   \n",
       "\n",
       "          user                                               text  \\\n",
       "0   BerryGurus  @BreeMe more time to play with you BlackBerry ...   \n",
       "1  peterlanoie  Failed attempt at booting to a flash drive. Th...   \n",
       "2  will_tooker  @msproductions Well ain't that the truth. Wher...   \n",
       "3   sammutimer  @Meaghery cheers Craig - that was really sweet...   \n",
       "4   ohaijustin  I was reading the tweets that got send to me w...   \n",
       "\n",
       "                                           sanitized  \n",
       "0                               time play blackberri  \n",
       "1  fail attempt boot flash drive fail attempt swi...  \n",
       "2  well truth damn auto lock disabl go copi past ...  \n",
       "3               cheer craig realli sweet repli pump   \n",
       "4  read tweet got send lie phone face drop amp hi...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_san.shape)\n",
    "df_san.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4388947b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before sanitizing 18398298\n",
      "After sanitizing 9575942\n"
     ]
    }
   ],
   "source": [
    "print(\"Before sanitizing\", df['text'].apply(lambda x: len(x.split(' '))).sum())\n",
    "print(\"After sanitizing\", df_san['sanitized'].apply(lambda x: len(x.split(' '))).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a17d2b",
   "metadata": {},
   "source": [
    "Just to check, we see that before sanitizing, we had 18'398'298 words. We were able to halve it to 9'575'942 by sanitization and stemming our tweets.\n",
    "\n",
    "Before fitting our models, we also take a subsample to be able to compute them faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc9f8e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Id 423388\n",
      "Last Id 63949\n",
      "Length 128000\n"
     ]
    }
   ],
   "source": [
    "df_sub = df_san.sample(frac=.1, random_state=SEED)\n",
    "\n",
    "# To check reproducibility\n",
    "print(\"First Id\", df_sub[\"Id\"].iloc[0])\n",
    "print(\"Last Id\", df_sub[\"Id\"].iloc[-1])\n",
    "print(\"Length\", df_sub.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dc0a54",
   "metadata": {},
   "source": [
    "# 2. Fitting\n",
    "\n",
    "Now that we have a subsample (10%) of our cleaned data, we can try to fit some models to see what it gives us. We also define a standard 10 kfolds which we will use for our cross-validation. \n",
    "\n",
    "Just as a note to justify the 10% choice for our sample. The bernoulli classifier below achieves, with default settings, an accuracy score of `76.37%` when using the whole dataset. For 10% of the dataset, the accuracy drops to `75.24%`. A 1% drop in accuracy for 10 times less computation time seems worth it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d2cb266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_sub[\"sanitized\"], df_sub[\"emotion\"], \n",
    "                                                    test_size=0.2, shuffle=True, random_state=SEED)\n",
    "\n",
    "#only 4 folds because I have 4 cores, just to test\n",
    "folds = KFold(n_splits=4, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd1c34c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (102400,)\n",
      "X_test:  (25600,)\n",
      "y_train:  (102400,)\n",
      "y_test:  (25600,)\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578b507c",
   "metadata": {},
   "source": [
    "First model we will try is the `BernoulliNB` since we have binary data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f46c4520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 2.1540353298187256\n",
      "Mean CV accuracy: 0.7483203125\n",
      "Test accuracy: 0.7523828125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nWhole dataset:\\nTime 21.568854093551636\\nMean CV accuracy: 0.7639306640625\\nTest accuracy: 0.76375390625\\n\\n10% sample:\\nTime 2.146036386489868\\nMean CV accuracy: 0.7483203125\\nTest accuracy: 0.7523828125\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berNB = Pipeline(\n",
    "    [\n",
    "        (\"tfidf\", TfidfVectorizer()),\n",
    "        (\"clf\", BernoulliNB()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "CV_ber = cross_val_score(\n",
    "    berNB, X_train, y_train, scoring=\"accuracy\", cv=folds, n_jobs=JOBS\n",
    ")\n",
    "\n",
    "berNB.fit(X_train, y_train)\n",
    "y_pred = berNB.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(f\"Time {time.time() - start}\")\n",
    "print(f\"Mean CV accuracy: {np.mean(CV_ber)}\")\n",
    "print(f\"Test accuracy: {score}\")\n",
    "\n",
    "\"\"\"\n",
    "Whole dataset:\n",
    "Time 21.568854093551636\n",
    "Mean CV accuracy: 0.7639306640625\n",
    "Test accuracy: 0.76375390625\n",
    "\n",
    "10% sample:\n",
    "Time 2.146036386489868\n",
    "Mean CV accuracy: 0.7483203125\n",
    "Test accuracy: 0.7523828125\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe6ab78",
   "metadata": {},
   "source": [
    "Without any paramter tuning, we got 75% with the naive Bayes Bernoulli classifier.\n",
    "Baseline is `0.77309`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30134494",
   "metadata": {},
   "source": [
    "No matter the alpha, we don't seem to get higher than 0.75. BernoulliNB is not the best model here.\n",
    "Instead of having to write the same for every model, let's try to automatize the testing just by specifying the model and the parameters grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "541d6ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LogisticRegression(warm_start=True)]\n",
    "models = [SGDClassifier(warm_start=True)]\n",
    "models = [BaggingClassifier(warm_start=True)]\n",
    "models = [RandomForestClassifier(warm_start=True)]\n",
    "models = [BaggingClassifier(warm_start=True)]\n",
    "models = [SVC()]\n",
    "models = [LinearSVC()]\n",
    "models = [RidgeClassifier()]\n",
    "models = [BernoulliNB()]\n",
    "\n",
    "params_tfid = {\n",
    "    \"tfidfvectorizer__norm\": [\"l2\"],\n",
    "    \"tfidfvectorizer__analyzer\": [\"word\"],\n",
    "    \"tfidfvectorizer__ngram_range\": [(1,2)],\n",
    "    \"tfidfvectorizer__max_df\": [0.95],\n",
    "    \"tfidfvectorizer__min_df\": [9],\n",
    "    #\"tfidfvectorizer__use_idf\": [True, False],\n",
    "    #\"tfidfvectorizer__smooth_idf\": [True, False],\n",
    "    #\"tfidfvectorizer__sublinear_tf\": [True, False]\n",
    "}\n",
    "params_countvectorizer = {\n",
    "    \"countvectorizer__lowercase\": [True],\n",
    "    \"countvectorizer__analyzer\": [\"word\"],\n",
    "    \"countvectorizer__ngram_range\": [(1,3)],\n",
    "    \"countvectorizer__max_df\": [1.0],\n",
    "    \"countvectorizer__min_df\": [1],\n",
    "    \"countvectorizer__binary\": [True]\n",
    "}\n",
    "\n",
    "#From Shiva's code\n",
    "#CountVectorizer(lowercase=True, stop_words=None, ngram_range=(1, 3), analyzer='word', max_df=1.0, min_df=1, binary=True)\n",
    "\n",
    "params = {\n",
    "    \"bernoullinb\": {\n",
    "        #\"bernoullinb__alpha\": np.linspace(0.1, 10, 10),\n",
    "        #\"bernoullinb__fit_prior\": [True],\n",
    "        **params_countvectorizer\n",
    "    },\n",
    "    \"ridgeclassifier\": {\n",
    "        \"ridgeclassifier__alpha\": np.linspace(1e-5, 10, 5),\n",
    "        \"ridgeclassifier__class_weight\": [\"balanced\", None],\n",
    "        \"ridgeclassifier__normalize\": [False, True],\n",
    "    },\n",
    "    \"logisticregression\": {\n",
    "        #\"logisticregression__penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
    "        \"logisticregression__penalty\": [\"l1\"],\n",
    "        #\"logisticregression__dual\": [False, True], try with liblinear\n",
    "        \"logisticregression__C\": 10**np.linspace(-3, -0.001, 4),\n",
    "        #\"logisticregression__C\": [1e-1],\n",
    "        \"logisticregression__random_state\": [SEED],\n",
    "        #\"logisticregression__solver\": [\"newton-cg\", \"lbfgs\", \"saga\"],\n",
    "        \"logisticregression__solver\": [\"saga\"],\n",
    "        #\"logisticregression__l1_ratio\": np.linspace(0.1, 0.9, 5),\n",
    "    },\n",
    "    \"sgdclassifier\": {\n",
    "        \"sgdclassifier__random_state\": [SEED],\n",
    "        \"sgdclassifier__loss\": [\"modified_huber\"],\n",
    "        \"sgdclassifier__alpha\": 10**np.linspace(-3, -0.001, 4),\n",
    "    },\n",
    "    \"baggingclassifier\": {\n",
    "        \"baggingclassifier__random_state\": [SEED],\n",
    "        \"baggingclassifier__n_estimators\": [30],\n",
    "        \"baggingclassifier__max_samples\": [0.05],\n",
    "        \"baggingclassifier__max_features\": [0.5],\n",
    "        \n",
    "    },\n",
    "    \"randomforestclassifier\": {\n",
    "        \"randomforestclassifier__random_state\": [SEED],\n",
    "    },\n",
    "    \"svc\": {\n",
    "        \"svc__random_state\": [SEED],\n",
    "    },\n",
    "    \"linearsvc\": {\n",
    "        \"linearsvc__random_state\": [SEED],\n",
    "        \"linearsvc__loss\": [\"squared_hinge\"],\n",
    "        \"linearsvc__penalty\": [\"l2\"],\n",
    "        \"linearsvc__max_iter\": [1000],\n",
    "        \"linearsvc__dual\": [False],\n",
    "        \"linearsvc__C\": np.linspace(0.01, 0.2, 10),\n",
    "        \"linearsvc__class_weight\": [\"balanced\"],\n",
    "    }\n",
    "}\n",
    "\n",
    "# If we also want to gridsearch the different Tfidf params\n",
    "for k, v in params_tfid.items():\n",
    "    #params[\"bernoullinb\"][k] = v\n",
    "    #Easier if we comment above\n",
    "    pass\n",
    "\n",
    "pipes = []\n",
    "\n",
    "# Also check what we can do with the TfidfVectorizer parameters\n",
    "for model in models:\n",
    "    #pipe = make_pipeline(TfidfVectorizer(), model)\n",
    "    pipe = make_pipeline((CountVectorizer(), model)\n",
    "    pipes.append(pipe)\n",
    "    \n",
    "    # Will use that once we have the best params\n",
    "    #pipe.set_params(**params[pipe.steps[1][0]])\n",
    "\n",
    "# Initialize empty dictionary\n",
    "reports = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02cf13d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bernoullinb\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-4ee5654d1f0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m#Grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mgridsearch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfolds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mJOBS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mvect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgridsearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vect'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgridsearch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "# Fit each different pipeline\n",
    "\n",
    "for pipe in pipes:\n",
    "    print(pipe.steps[1][0])\n",
    "    start = time.time()\n",
    "    \n",
    "    gridsearch = GridSearchCV(pipe, params[pipe.steps[1][0]], scoring=\"accuracy\", cv=folds, n_jobs=JOBS, verbose=3)\n",
    "    gridsearch.fit(X_train, y_train)\n",
    "    y_pred = gridsearch.predict(X_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    resdf = pd.DataFrame(gridsearch.cv_results_)\n",
    "    \n",
    "    reports[pipe.steps[1][0]] = classification_report(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Time {time.time() - start}s\")\n",
    "    #print(resdf[resdf[\"rank_test_score\"] == 1])\n",
    "    print(f\"Test accuracy: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "013470c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_tfidfvectorizer__analyzer</th>\n",
       "      <th>param_tfidfvectorizer__max_df</th>\n",
       "      <th>param_tfidfvectorizer__min_df</th>\n",
       "      <th>param_tfidfvectorizer__ngram_range</th>\n",
       "      <th>param_tfidfvectorizer__norm</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.726366</td>\n",
       "      <td>0.184122</td>\n",
       "      <td>1.006197</td>\n",
       "      <td>0.126528</td>\n",
       "      <td>word</td>\n",
       "      <td>0.95</td>\n",
       "      <td>9</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'tfidfvectorizer__analyzer': 'word', 'tfidfve...</td>\n",
       "      <td>0.748984</td>\n",
       "      <td>0.751406</td>\n",
       "      <td>0.752656</td>\n",
       "      <td>0.754141</td>\n",
       "      <td>0.751797</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.694935</td>\n",
       "      <td>1.599764</td>\n",
       "      <td>0.832412</td>\n",
       "      <td>0.080307</td>\n",
       "      <td>word</td>\n",
       "      <td>0.95</td>\n",
       "      <td>9</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'tfidfvectorizer__analyzer': 'word', 'tfidfve...</td>\n",
       "      <td>0.748906</td>\n",
       "      <td>0.751172</td>\n",
       "      <td>0.752188</td>\n",
       "      <td>0.753984</td>\n",
       "      <td>0.751562</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       7.726366      0.184122         1.006197        0.126528   \n",
       "1       9.694935      1.599764         0.832412        0.080307   \n",
       "\n",
       "  param_tfidfvectorizer__analyzer param_tfidfvectorizer__max_df  \\\n",
       "0                            word                          0.95   \n",
       "1                            word                          0.95   \n",
       "\n",
       "  param_tfidfvectorizer__min_df param_tfidfvectorizer__ngram_range  \\\n",
       "0                             9                             (1, 2)   \n",
       "1                             9                             (1, 3)   \n",
       "\n",
       "  param_tfidfvectorizer__norm  \\\n",
       "0                          l2   \n",
       "1                          l2   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'tfidfvectorizer__analyzer': 'word', 'tfidfve...           0.748984   \n",
       "1  {'tfidfvectorizer__analyzer': 'word', 'tfidfve...           0.748906   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  mean_test_score  \\\n",
       "0           0.751406           0.752656           0.754141         0.751797   \n",
       "1           0.751172           0.752188           0.753984         0.751562   \n",
       "\n",
       "   std_test_score  rank_test_score  \n",
       "0        0.001890                1  \n",
       "1        0.001835                2  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resdf.sort_values(by=[\"rank_test_score\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a7fce",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "Linear models: <br>\n",
    "BernoulliNB: 0.76 <br>\n",
    "LogisticRegression: <br>\n",
    "    l2 - 0.76 <br>\n",
    "    l2, C range - 0.76 <br>\n",
    "    elasticnet, C range, l1_ratio range - 0.75 <br>\n",
    "    l1, C=0.1 - 0.74 <br>\n",
    "    l1, C range - 0.76 <br>\n",
    "sgdclassifier: <br>\n",
    "    all default - 0.75 <br>\n",
    "    modified_huber - 0.75 <br>\n",
    "ridgeclassifier: <br>\n",
    "    alpha=7.5, class_weight=balanced, normalize=False -> 0.76\n",
    "    \n",
    "Linear models seem not to perform better than around 0.75. Let's go to ensembles.\n",
    "\n",
    "Ensemble: <br>\n",
    "RandomForestClassifier: <br>\n",
    "    max_samples 0.001 - 0.59 <br>\n",
    "    max_samples 0.1 - 0.71 <br>\n",
    "    max_samples 0.8 - 0.73 <br>\n",
    "    max_samples 0.01, n_estimators 40 - 0.71 <br>\n",
    "    max_samples 0.01, n_estimators 20 - 0.68 <br>\n",
    "    max_samples 0.01, n_estimators 100 - 0.72 <br>\n",
    "    max_samples 0.1, n_estimators 50 - 0.74 <br>\n",
    "    max_samples 0.5, n_estimators 70 - 0.75 <br>\n",
    "    max_samples 0.1, n_estimators 150 - 0.75 <br>\n",
    "\n",
    "BaggingClassifier: <br>\n",
    "    max_samples 0.01, n_estimators 100 - 0.70 <br>\n",
    "    max_samples 0.1, n_estimators 10 - 0.72 <br>\n",
    "    max_samples 0.05, n_estimators 30 - 0.72 <br>\n",
    "    max_samples 0.05, n_estimators 30, max_features 0.5 - 0.72 <br>\n",
    "    \n",
    "SVC: -> not fast enough\n",
    " \n",
    "LinearSVC: <br>\n",
    "default: 0.75 -> really fast! <br>\n",
    "squared_hinge + dual=False + C=0.1 -> 0.76 <br>\n",
    "squared_hinge + dual=False + C=0.1 + class_weight=balanced -> 0.76\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f1d4f5",
   "metadata": {},
   "source": [
    "No matter the classifier, we don't seem to go above 76%. Look into the data to see if we can see something.\n",
    "-> delete very short tweets?\n",
    "-> lemmatization?\n",
    "\n",
    "Maybe deleted too much noise during preprocessing, only remove stopwords? (+URLs?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
