{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6a9c62b",
   "metadata": {},
   "source": [
    "## Lab\n",
    "\n",
    "_Marilyn, Shiva, Olivier_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "161968fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "683de196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup chunk\n",
    "\n",
    "import time\n",
    "\n",
    "# Custom utils\n",
    "from utils import *\n",
    "\n",
    "# Data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Text sanitization\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "try:\n",
    "    # Avoid error if you don't have the resource\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "except LookupError:\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download(\"stopwords\")\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    \n",
    "stemmer = SnowballStemmer(language=\"english\")\n",
    "\n",
    "# Lang detection\n",
    "#import langid\n",
    "#from langid.langid import LanguageIdentifier, model\n",
    "#identifier = LanguageIdentifier.from_modelstring(model, norm_probs=True)\n",
    "\n",
    "# Misc\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# Define the seed for reproducibility\n",
    "SEED = 31415\n",
    "\n",
    "# Define n_jobs\n",
    "JOBS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ca49014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit time\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import (\n",
    "    LinearDiscriminantAnalysis,\n",
    "    QuadraticDiscriminantAnalysis,\n",
    ")\n",
    "\n",
    "from sklearn.feature_extraction.text import (\n",
    "    CountVectorizer, \n",
    "    TfidfTransformer, \n",
    "    TfidfVectorizer\n",
    ")\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    GridSearchCV, \n",
    "    KFold, \n",
    "    cross_val_score\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    accuracy_score, \n",
    "    confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7332337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olivi\\anaconda3\\envs\\env\\lib\\site-packages\\numpy\\lib\\arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@BreeMe more time to play with you BlackBerry ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Failed attempt at booting to a flash drive. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@msproductions Well ain't that the truth. Wher...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@Meaghery cheers Craig - that was really sweet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I was reading the tweets that got send to me w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    emotion                                               text\n",
       "Id                                                            \n",
       "0         1  @BreeMe more time to play with you BlackBerry ...\n",
       "1         0  Failed attempt at booting to a flash drive. Th...\n",
       "2         0  @msproductions Well ain't that the truth. Wher...\n",
       "3         1  @Meaghery cheers Craig - that was really sweet...\n",
       "4         0  I was reading the tweets that got send to me w..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import df\n",
    "df = pd.read_csv(\"./data/MLUnige2021_train.csv\", index_col=\"Id\")\n",
    "df = df.drop(columns=[\"tweet_id\", \"date\", \"lyx_query\", \"user\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d356be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize3(txt: str) -> str:\n",
    "    \"\"\"Preprocess text\"\"\"\n",
    "    \n",
    "    # Regex patterns\n",
    "    urlPattern        = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "    userPattern       = r\"@[^\\s]+\"\n",
    "    alphaPattern      = \"[^a-zA-Z0-9]\"\n",
    "    sequencePattern   = r\"(.)\\1\\1+\"\n",
    "    seqReplacePattern = r\"\\1\\1\"\n",
    "    \n",
    "    # Lowercase\n",
    "    txt = txt.lower()\n",
    "    # Url\n",
    "    txt = re.sub(r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\", \" URL\", txt)\n",
    "    # Twitter handle\n",
    "    txt = re.sub(r\"@[^\\s]+\", \" USER\", txt)\n",
    "    # Remove non-alphanumeric chars\n",
    "    txt = re.sub(r\"[^a-zA-Z0-9]\", \" \", txt)\n",
    "    # Replace consecutive chars by 2 repetitions\n",
    "    txt = re.sub(r\"(.)\\1\\1+\", r\"\\1\\1\", txt)\n",
    "    \n",
    "    words = \"\"\n",
    "    for word in txt.split():\n",
    "        word = lemmatizer.lemmatize(word)\n",
    "        words += (word + \" \")\n",
    "    \n",
    "    return words    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fb3c6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 1280000/1280000 [02:39<00:00, 8025.90it/s]\n"
     ]
    }
   ],
   "source": [
    "df_san = df.copy()\n",
    "df_san[\"sanitized\"] = df[\"text\"].progress_apply(sanitize)\n",
    "\n",
    "# Export it to pickle so we don't have to redo it\n",
    "df_san.to_pickle(\"./data/sanitized3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3e941e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "      <th>sanitized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@BreeMe more time to play with you BlackBerry ...</td>\n",
       "      <td>usernam time play blackberri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Failed attempt at booting to a flash drive. Th...</td>\n",
       "      <td>fail attempt boot flash drive fail attempt swi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@msproductions Well ain't that the truth. Wher...</td>\n",
       "      <td>usernam well truth damn auto lock disabl go co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>@Meaghery cheers Craig - that was really sweet...</td>\n",
       "      <td>usernam cheer craig realli sweet repli pump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I was reading the tweets that got send to me w...</td>\n",
       "      <td>read tweet got send lie phone face drop amp hi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    emotion                                               text  \\\n",
       "Id                                                               \n",
       "0         1  @BreeMe more time to play with you BlackBerry ...   \n",
       "1         0  Failed attempt at booting to a flash drive. Th...   \n",
       "2         0  @msproductions Well ain't that the truth. Wher...   \n",
       "3         1  @Meaghery cheers Craig - that was really sweet...   \n",
       "4         0  I was reading the tweets that got send to me w...   \n",
       "\n",
       "                                            sanitized  \n",
       "Id                                                     \n",
       "0                        usernam time play blackberri  \n",
       "1   fail attempt boot flash drive fail attempt swi...  \n",
       "2   usernam well truth damn auto lock disabl go co...  \n",
       "3        usernam cheer craig realli sweet repli pump   \n",
       "4   read tweet got send lie phone face drop amp hi...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_san.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ac8ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_san[\"sanitized\"], df_san[\"emotion\"], \n",
    "                                                    test_size=0.1, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6a38a861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.5, max_features=50000, min_df=9, ngram_range=(1, 2))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit vectorizer\n",
    "vect = TfidfVectorizer(max_df=0.5, max_features=50000, min_df=9, ngram_range=(1,2))\n",
    "vect.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a5925ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data\n",
    "X_train = vect.transform(X_train)\n",
    "X_test  = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6bef3f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 0.3360428810119629\n",
      "Test accuracy: 0.77121875\n"
     ]
    }
   ],
   "source": [
    "#BerNB\n",
    "start = time.time()\n",
    "\n",
    "ber = BernoulliNB(alpha=2)\n",
    "ber.fit(X_train, y_train)\n",
    "y_pred = ber.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Time {time.time() - start}\")\n",
    "print(f\"Test accuracy: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a262c26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 23.18459463119507\n",
      "Test accuracy: 0.7836328125\n"
     ]
    }
   ],
   "source": [
    "#LinearSVC\n",
    "start = time.time()\n",
    "\n",
    "svc = LinearSVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Time {time.time() - start}\")\n",
    "print(f\"Test accuracy: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41082d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 15.302069902420044\n",
      "Test accuracy: 0.7864140625\n"
     ]
    }
   ],
   "source": [
    "#LinearSVC\n",
    "start = time.time()\n",
    "\n",
    "logreg = LogisticRegression(C=2, n_jobs=-1)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Time {time.time() - start}\")\n",
    "print(f\"Test accuracy: {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
